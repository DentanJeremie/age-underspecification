
@misc{lee_diversify_2022,
	title = {Diversify and {Disambiguate}: {Learning} {From} {Underspecified} {Data}},
	shorttitle = {Diversify and {Disambiguate}},
	url = {http://arxiv.org/abs/2202.03418},
	doi = {10.48550/arXiv.2202.03418},
	abstract = {Many datasets are underspecified: there exist multiple equally viable solutions to a given task. Underspecification can be problematic for methods that learn a single hypothesis because different functions that achieve low training loss can focus on different predictive features and thus produce widely varying predictions on out-of-distribution data. We propose DivDis, a simple two-stage framework that first learns a diverse collection of hypotheses for a task by leveraging unlabeled data from the test distribution. We then disambiguate by selecting one of the discovered hypotheses using minimal additional supervision, in the form of additional labels or inspection of function visualization. We demonstrate the ability of DivDis to find hypotheses that use robust features in image classification and natural language processing problems with underspecification.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Lee, Yoonho and Yao, Huaxiu and Finn, Chelsea},
	month = jun,
	year = {2022},
	note = {arXiv:2202.03418 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/5ZRRWWVX/Lee et al. - 2022 - Diversify and Disambiguate Learning From Underspe.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/3DIA98LM/2202.html:text/html},
}

@misc{qawaqneh_deep_2017,
	title = {Deep {Convolutional} {Neural} {Network} for {Age} {Estimation} based on {VGG}-{Face} {Model}},
	url = {http://arxiv.org/abs/1709.01664},
	abstract = {Automatic age estimation from real-world and unconstrained face images is rapidly gaining importance. In our proposed work, a deep CNN model that was trained on a database for face recognition task is used to estimate the age information on the Adience database. This paper has three significant contributions in this field. (1) This work proves that a CNN model, which was trained for face recognition task, can be utilized for age estimation to improve performance; (2) Over fitting problem can be overcome by employing a pretrained CNN on a large database for face recognition task; (3) Not only the number of training images and the number subjects in a training database effect the performance of the age estimation model, but also the pre-training task of the employed CNN determines the performance of the model.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Qawaqneh, Zakariya and Mallouh, Arafat Abu and Barkana, Buket D.},
	month = sep,
	year = {2017},
	note = {arXiv:1709.01664 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/S9IY4ZR8/Qawaqneh et al. - 2017 - Deep Convolutional Neural Network for Age Estimati.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/NF8JW2AY/1709.html:text/html},
}

@misc{lee_divdis_2023,
	title = {{DivDis}},
	copyright = {MIT},
	url = {https://github.com/yoonholee/DivDis},
	urldate = {2023-02-07},
	author = {Lee, Yoonho},
	month = feb,
	year = {2023},
	note = {original-date: 2022-06-20T02:21:29Z},
}

@inproceedings{nga_transfer_2020,
	title = {Transfer {Learning} for {Gender} and {Age} {Prediction}},
	doi = {10.1109/ICCE-Taiwan49838.2020.9258347},
	abstract = {In this work, we propose a transfer learning pipeline for gender and age prediction using images from IMDB-WIKI dataset. Firstly, we freeze all layers in pre-trained ImageNet models. Then, the models are trained for four stages with scheduled learning rates and the blocks of layers are unlocked consecutively in accordance to the schedule. We apply multi-output neural network paradigm to predict age and gender simultaneously and the final loss function is based on the combination of age and gender losses. In our approach, the model has better performance than that of the non-pre-trained model because the later stages of our models reuse features extracted from the pre-trained early stages.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Consumer} {Electronics} - {Taiwan} ({ICCE}-{Taiwan})},
	author = {Nga, Cao Hong and Nguyen, Khai-Thinh and Tran, Nghi C. and Wang, Jia-Ching},
	month = sep,
	year = {2020},
	note = {ISSN: 2575-8284},
	keywords = {Training, age and gender prediction, Computational modeling, Conferences, convolutional neural network, Faces, neural networks, Predictive models, Residual neural networks, Sun, transfer learning},
	pages = {1--2},
	file = {IEEE Xplore Abstract Record:/Users/jeremie/Zotero/storage/7YBBCC25/9258347.html:text/html},
}

@misc{damour_underspecification_2020,
	title = {Underspecification {Presents} {Challenges} for {Credibility} in {Modern} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2011.03395},
	doi = {10.48550/arXiv.2011.03395},
	abstract = {ML models often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification as a key reason for these failures. An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. Underspecification is common in modern ML pipelines, such as those based on deep learning. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We show that this problem appears in a wide variety of practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {D'Amour, Alexander and Heller, Katherine and Moldovan, Dan and Adlam, Ben and Alipanahi, Babak and Beutel, Alex and Chen, Christina and Deaton, Jonathan and Eisenstein, Jacob and Hoffman, Matthew D. and Hormozdiari, Farhad and Houlsby, Neil and Hou, Shaobo and Jerfel, Ghassen and Karthikesalingam, Alan and Lucic, Mario and Ma, Yian and McLean, Cory and Mincu, Diana and Mitani, Akinori and Montanari, Andrea and Nado, Zachary and Natarajan, Vivek and Nielson, Christopher and Osborne, Thomas F. and Raman, Rajiv and Ramasamy, Kim and Sayres, Rory and Schrouff, Jessica and Seneviratne, Martin and Sequeira, Shannon and Suresh, Harini and Veitch, Victor and Vladymyrov, Max and Wang, Xuezhi and Webster, Kellie and Yadlowsky, Steve and Yun, Taedong and Zhai, Xiaohua and Sculley, D.},
	month = nov,
	year = {2020},
	note = {arXiv:2011.03395 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/4JJBIRTN/D'Amour et al. - 2020 - Underspecification Presents Challenges for Credibi.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/U6TYP2J4/2011.html:text/html},
}

@misc{hiba_hierarchical_2021,
	title = {Hierarchical {Attention}-based {Age} {Estimation} and {Bias} {Estimation}},
	url = {http://arxiv.org/abs/2103.09882},
	abstract = {In this work we propose a novel deep-learning approach for age estimation based on face images. We first introduce a dual image augmentation-aggregation approach based on attention. This allows the network to jointly utilize multiple face image augmentations whose embeddings are aggregated by a Transformer-Encoder. The resulting aggregated embedding is shown to better encode the face image attributes. We then propose a probabilistic hierarchical regression framework that combines a discrete probabilistic estimate of age labels, with a corresponding ensemble of regressors. Each regressor is particularly adapted and trained to refine the probabilistic estimate over a range of ages. Our scheme is shown to outperform contemporary schemes and provide a new state-of-the-art age estimation accuracy, when applied to the MORPH II dataset for age estimation. Last, we introduce a bias analysis of state-of-the-art age estimation results.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Hiba, Shakediel and Keller, Yosi},
	month = mar,
	year = {2021},
	note = {arXiv:2103.09882 [cs]
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/93ZX9MW5/Hiba et Keller - 2021 - Hierarchical Attention-based Age Estimation and Bi.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/ZH85PCWS/2103.html:text/html},
}

@misc{li_trocr_2022,
	title = {{TrOCR}: {Transformer}-based {Optical} {Character} {Recognition} with {Pre}-trained {Models}},
	shorttitle = {{TrOCR}},
	url = {http://arxiv.org/abs/2109.10282},
	doi = {10.48550/arXiv.2109.10282},
	abstract = {Text recognition is a long-standing research problem for document digitalization. Existing approaches are usually built based on CNN for image understanding and RNN for char-level text generation. In addition, another language model is usually needed to improve the overall accuracy as a post-processing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on the printed, handwritten and scene text recognition tasks. The TrOCR models and code are publicly available at {\textbackslash}url\{https://aka.ms/trocr\}.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu},
	month = sep,
	year = {2022},
	note = {arXiv:2109.10282 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/FPMDAPJX/Li et al. - 2022 - TrOCR Transformer-based Optical Character Recogni.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/3WJ2YA32/2109.html:text/html},
}

@misc{lin_transferring_2022,
	title = {Transferring {General} {Multimodal} {Pretrained} {Models} to {Text} {Recognition}},
	url = {http://arxiv.org/abs/2212.09297},
	doi = {10.48550/arXiv.2212.09297},
	abstract = {This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained models to text recognition. Specifically, we recast text recognition as image captioning and directly transfer a unified vision-language pretrained model to the end task. Without pretraining on large-scale annotated or synthetic text recognition data, OFA-OCR outperforms the baselines and achieves state-of-the-art performance in the Chinese text recognition benchmark. Additionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate that it can achieve competitive performance with the product-level API. The code (https://github.com/OFA-Sys/OFA) and demo (https://modelscope.cn/studios/damo/ofa\_ocr\_pipeline/summary) are publicly available.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Lin, Junyang and Ren, Xuancheng and Zhang, Yichang and Liu, Gao and Wang, Peng and Yang, An and Zhou, Chang},
	month = dec,
	year = {2022},
	note = {arXiv:2212.09297 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/79YU4Z7Q/Lin et al. - 2022 - Transferring General Multimodal Pretrained Models .pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/J3DX6PMX/2212.html:text/html},
}

@misc{noauthor_tesseract_2023,
	title = {Tesseract {OCR}},
	copyright = {Apache-2.0},
	url = {https://github.com/tesseract-ocr/tesseract},
	abstract = {Tesseract Open Source OCR Engine (main repository)},
	urldate = {2023-03-13},
	publisher = {tesseract-ocr},
	month = mar,
	year = {2023},
	note = {original-date: 2014-08-12T18:04:59Z},
	keywords = {hacktoberfest, lstm, machine-learning, ocr, ocr-engine, tesseract, tesseract-ocr},
}

@misc{amodei_concrete_2016,
	title = {Concrete {Problems} in {AI} {Safety}},
	url = {http://arxiv.org/abs/1606.06565},
	doi = {10.48550/arXiv.1606.06565},
	abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Mané, Dan},
	month = jul,
	year = {2016},
	note = {arXiv:1606.06565 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/TLM9LI58/Amodei et al. - 2016 - Concrete Problems in AI Safety.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/N3MA4BF4/1606.html:text/html},
}

@misc{oakden-rayner_hidden_2019,
	title = {Hidden {Stratification} {Causes} {Clinically} {Meaningful} {Failures} in {Machine} {Learning} for {Medical} {Imaging}},
	url = {http://arxiv.org/abs/1909.12475},
	doi = {10.48550/arXiv.1909.12475},
	abstract = {Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model still consistently misses a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring and describing hidden stratification effects, and characterize these effects on multiple medical imaging datasets. We find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20\% on clinically important subsets. Finally, we explore the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Oakden-Rayner, Luke and Dunnmon, Jared and Carneiro, Gustavo and Ré, Christopher},
	month = nov,
	year = {2019},
	note = {arXiv:1909.12475 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/82YTMTR7/Oakden-Rayner et al. - 2019 - Hidden Stratification Causes Clinically Meaningful.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/433VZQHL/1909.html:text/html},
}

@misc{arpit_closer_2017,
	title = {A {Closer} {Look} at {Memorization} in {Deep} {Networks}},
	url = {http://arxiv.org/abs/1706.05394},
	doi = {10.48550/arXiv.1706.05394},
	abstract = {We examine the role of memorization in deep learning, drawing connections to capacity, generalization, and adversarial robustness. While deep networks are capable of memorizing noise data, our results suggest that they tend to prioritize learning simple patterns first. In our experiments, we expose qualitative differences in gradient-based optimization of deep neural networks (DNNs) on noise vs. real data. We also demonstrate that for appropriately tuned explicit regularization (e.g., dropout) we can degrade DNN training performance on noise datasets without compromising generalization on real data. Our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Arpit, Devansh and Jastrzębski, Stanisław and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S. and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and Lacoste-Julien, Simon},
	month = jul,
	year = {2017},
	note = {arXiv:1706.05394 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/J25ZTEXX/Arpit et al. - 2017 - A Closer Look at Memorization in Deep Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/BBHMLVT8/1706.html:text/html},
}

@misc{gunasekar_implicit_2019,
	title = {Implicit {Bias} of {Gradient} {Descent} on {Linear} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1806.00468},
	doi = {10.48550/arXiv.1806.00468},
	abstract = {We show that gradient descent on full-width linear convolutional networks of depth \$L\$ converges to a linear predictor related to the \${\textbackslash}ell\_\{2/L\}\$ bridge penalty in the frequency domain. This is in contrast to linearly fully connected networks, where gradient descent converges to the hard margin linear support vector machine solution, regardless of depth.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
	month = jan,
	year = {2019},
	note = {arXiv:1806.00468 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/SUFMWQ9C/Gunasekar et al. - 2019 - Implicit Bias of Gradient Descent on Linear Convol.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/AVZY5VIH/1806.html:text/html},
}

@misc{tzeng_deep_2014,
	title = {Deep {Domain} {Confusion}: {Maximizing} for {Domain} {Invariance}},
	shorttitle = {Deep {Domain} {Confusion}},
	url = {http://arxiv.org/abs/1412.3474},
	doi = {10.48550/arXiv.1412.3474},
	abstract = {Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
	month = dec,
	year = {2014},
	note = {arXiv:1412.3474 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/4X3V9K3B/Tzeng et al. - 2014 - Deep Domain Confusion Maximizing for Domain Invar.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/AZFQ34MB/1412.html:text/html},
}

@misc{ganin_domain-adversarial_2016,
	title = {Domain-{Adversarial} {Training} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.07818},
	doi = {10.48550/arXiv.1505.07818},
	abstract = {We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
	month = may,
	year = {2016},
	note = {arXiv:1505.07818 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/KZRNVIG4/Ganin et al. - 2016 - Domain-Adversarial Training of Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/4INFNFGP/1505.html:text/html},
}

@misc{arjovsky_invariant_2020,
	title = {Invariant {Risk} {Minimization}},
	url = {http://arxiv.org/abs/1907.02893},
	doi = {10.48550/arXiv.1907.02893},
	abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
	month = mar,
	year = {2020},
	note = {arXiv:1907.02893 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/GRJSYWCD/Arjovsky et al. - 2020 - Invariant Risk Minimization.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/9FRWA55U/1907.html:text/html},
}

@misc{sagawa_distributionally_2020,
	title = {Distributionally {Robust} {Neural} {Networks} for {Group} {Shifts}: {On} the {Importance} of {Regularization} for {Worst}-{Case} {Generalization}},
	shorttitle = {Distributionally {Robust} {Neural} {Networks} for {Group} {Shifts}},
	url = {http://arxiv.org/abs/1911.08731},
	doi = {10.48550/arXiv.1911.08731},
	abstract = {Overparameterized neural networks can be highly accurate on average on an i.i.d. test set yet consistently fail on atypical groups of the data (e.g., by learning spurious correlations that hold on average but not in such groups). Distributionally robust optimization (DRO) allows us to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. However, we find that naively applying group DRO to overparameterized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, the poor worst-case performance arises from poor generalization on some groups. By coupling group DRO models with increased regularization---a stronger-than-typical L2 penalty or early stopping---we achieve substantially higher worst-group accuracies, with 10-40 percentage point improvements on a natural language inference task and two image tasks, while maintaining high average accuracies. Our results suggest that regularization is important for worst-group generalization in the overparameterized regime, even if it is not needed for average generalization. Finally, we introduce a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRO models.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B. and Liang, Percy},
	month = apr,
	year = {2020},
	note = {arXiv:1911.08731 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/IRQDZU47/Sagawa et al. - 2020 - Distributionally Robust Neural Networks for Group .pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/2J8K8VZZ/1911.html:text/html},
}

@misc{nam_learning_2020,
	title = {Learning from {Failure}: {Training} {Debiased} {Classifier} from {Biased} {Classifier}},
	shorttitle = {Learning from {Failure}},
	url = {http://arxiv.org/abs/2007.02561},
	doi = {10.48550/arXiv.2007.02561},
	abstract = {Neural networks often learn to make predictions that overly rely on spurious correlation existing in the dataset, which causes the model to be biased. While previous work tackles this issue by using explicit labeling on the spuriously correlated attributes or presuming a particular bias type, we instead utilize a cheaper, yet generic form of human knowledge, which can be widely applicable to various types of bias. We first observe that neural networks learn to rely on the spurious correlation only when it is "easier" to learn than the desired knowledge, and such reliance is most prominent during the early phase of training. Based on the observations, we propose a failure-based debiasing scheme by training a pair of neural networks simultaneously. Our main idea is twofold; (a) we intentionally train the first network to be biased by repeatedly amplifying its "prejudice", and (b) we debias the training of the second network by focusing on samples that go against the prejudice of the biased network in (a). Extensive experiments demonstrate that our method significantly improves the training of the network against various types of biases in both synthetic and real-world datasets. Surprisingly, our framework even occasionally outperforms the debiasing methods requiring explicit supervision of the spuriously correlated attributes.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Nam, Junhyun and Cha, Hyuntak and Ahn, Sungsoo and Lee, Jaeho and Shin, Jinwoo},
	month = nov,
	year = {2020},
	note = {arXiv:2007.02561 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/THWIBI9J/Nam et al. - 2020 - Learning from Failure Training Debiased Classifie.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/PXPTH73P/2007.html:text/html},
}

@misc{liu_just_2021,
	title = {Just {Train} {Twice}: {Improving} {Group} {Robustness} without {Training} {Group} {Information}},
	shorttitle = {Just {Train} {Twice}},
	url = {http://arxiv.org/abs/2107.09044},
	doi = {10.48550/arXiv.2107.09044},
	abstract = {Standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on certain groups, especially in the presence of spurious correlations between the input and label. Prior approaches that achieve high worst-group accuracy, like group distributionally robust optimization (group DRO) require expensive group annotations for each training point, whereas approaches that do not use such group annotations typically achieve unsatisfactory worst-group accuracy. In this paper, we propose a simple two-stage approach, JTT, that first trains a standard ERM model for several epochs, and then trains a second model that upweights the training examples that the first model misclassified. Intuitively, this upweights examples from groups on which standard ERM models perform poorly, leading to improved worst-group performance. Averaged over four image classification and natural language processing tasks with spurious correlations, JTT closes 75\% of the gap in worst-group accuracy between standard ERM and group DRO, while only requiring group annotations on a small validation set in order to tune hyperparameters.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Liu, Evan Zheran and Haghgoo, Behzad and Chen, Annie S. and Raghunathan, Aditi and Koh, Pang Wei and Sagawa, Shiori and Liang, Percy and Finn, Chelsea},
	month = sep,
	year = {2021},
	note = {arXiv:2107.09044 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/GMYCHA28/Liu et al. - 2021 - Just Train Twice Improving Group Robustness witho.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/WB8JW4AK/2107.html:text/html},
}

@misc{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2023-03-14},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv:1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/ZTVKQDFR/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/R9W6MV4B/1512.html:text/html},
}

@misc{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2023-03-14},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/GCCHJDT5/Simonyan et Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/CST7PCJS/1409.html:text/html},
}

@article{sudiatmika_image_2018,
	title = {Image forgery detection using error level analysis and deep learning},
	volume = {17},
	doi = {10.12928/telkomnika.v17i2.8976},
	journal = {TELKOMNIKA (Telecommunication Computing Electronics and Control)},
	author = {Sudiatmika, Ida and Rahman, Fathur and Trisno, Trisno and Suyoto, Suyoto},
	month = aug,
	year = {2018},
	pages = {653},
	file = {Full Text PDF:/Users/jeremie/Zotero/storage/5ABN6TT4/Sudiatmika et al. - 2018 - Image forgery detection using error level analysis.pdf:application/pdf},
}

@book{meyer_forensische_2012,
	title = {Forensische {Datenanalyse} : dolose {Handlungen} im {Unternehmen} erkennen und aufdecken},
	isbn = {978-3-503-13847-0},
	shorttitle = {Forensische {Datenanalyse}},
	language = {de},
	publisher = {Erich Schmidt},
	author = {Meyer, Jörg},
	year = {2012},
	note = {Google-Books-ID: V96iMAEACAAJ},
}

@article{skodras_jpeg_2001,
	title = {The {JPEG} 2000 still image compression standard},
	volume = {18},
	issn = {1558-0792},
	doi = {10.1109/79.952804},
	abstract = {One of the aims of the standardization committee has been the development of Part I, which could be used on a royalty- and fee-free basis. This is important for the standard to become widely accepted. The standardization process, which is coordinated by the JTCI/SC29/WG1 of the ISO/IEC has already produced the international standard (IS) for Part I. In this article the structure of Part I of the JPFG 2000 standard is presented and performance comparisons with established standards are reported. This article is intended to serve as a tutorial for the JPEG 2000 standard. The main application areas and their requirements are given. The architecture of the standard follows with the description of the tiling, multicomponent transformations, wavelet transforms, quantization and entropy coding. Some of the most significant features of the standard are presented, such as region-of-interest coding, scalability, visual weighting, error resilience and file format aspects. Finally, some comparative results are reported and the future parts of the standard are discussed.},
	number = {5},
	journal = {IEEE Signal Processing Magazine},
	author = {Skodras, A. and Christopoulos, C. and Ebrahimi, T.},
	month = sep,
	year = {2001},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Entropy coding, IEC standards, Image coding, ISO standards, Quantization, Resilience, Scalability, Standardization, Transform coding, Wavelet transforms},
	pages = {36--58},
	file = {IEEE Xplore Abstract Record:/Users/jeremie/Zotero/storage/S2CWBQN4/952804.html:text/html;Texte intégral:/Users/jeremie/Zotero/storage/MG6S27JU/Skodras et al. - 2001 - The JPEG 2000 still image compression standard.pdf:application/pdf},
}

@inproceedings{deng_imagenet_2009,
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	shorttitle = {{ImageNet}},
	doi = {10.1109/CVPR.2009.5206848},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	booktitle = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	month = jun,
	year = {2009},
	note = {ISSN: 1063-6919},
	keywords = {Explosions, Image databases, Image retrieval, Information retrieval, Internet, Large-scale systems, Multimedia databases, Ontologies, Robustness, Spine},
	pages = {248--255},
	file = {IEEE Xplore Abstract Record:/Users/jeremie/Zotero/storage/3KFUQ93T/5206848.html:text/html},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2023-03-15},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/AWU56M8H/Kingma et Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf},
}